{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T15:10:14.703968Z",
     "start_time": "2021-11-07T15:10:14.699160Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature Extraction\n",
    "\n",
    "In order to feed text to a model we need to transform it to a numerical features, in this notebook we will discuss how to build a bag-of-words model from text to use it later for different applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bag of words\n",
    "\n",
    "Count the occurrences of words in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T22:21:27.519144Z",
     "start_time": "2021-11-07T22:21:25.778819Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>eats</th>\n",
       "      <th>food</th>\n",
       "      <th>hot</th>\n",
       "      <th>red</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the red dog</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat eats dog</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog eats food</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red cat eats</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the hot dog</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cat  dog  eats  food  hot  red  the\n",
       "the red dog      0    1     0     0    0    1    1\n",
       "cat eats dog     1    1     1     0    0    0    0\n",
       "dog eats food    0    1     1     1    0    0    0\n",
       "red cat eats     1    0     1     0    0    1    0\n",
       "the hot dog      0    1     0     0    1    0    1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "texts = [ 'the red dog', 'cat eats dog', 'dog eats food',\n",
    "         'red cat eats', 'the hot dog']\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(texts)\n",
    "x = vectorizer.transform(texts)\n",
    "columns = vectorizer.get_feature_names()\n",
    "pd.DataFrame(x.todense(), columns=columns, index=texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stop-words\n",
    "\n",
    "Stop-words are words that are not significant to the topic in hand, for example `[am, is, are, in, at, ...]` can be considered stop-words in many applications as they don't add meaning.\n",
    "\n",
    "In some other domains and problems you may have different kind of stop-words, for example if you are processing some chatbot data you may find `[can you please, would you please, can I, may I, ...]` such examples don't add meaning so stop-words can also be domain specific, and `TFIDF` can help you find these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T22:21:27.530376Z",
     "start_time": "2021-11-07T22:21:27.520724Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>eats</th>\n",
       "      <th>food</th>\n",
       "      <th>hot</th>\n",
       "      <th>red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the red dog</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat eats dog</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog eats food</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red cat eats</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the hot dog</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cat  dog  eats  food  hot  red\n",
       "the red dog      0    1     0     0    0    1\n",
       "cat eats dog     1    1     1     0    0    0\n",
       "dog eats food    0    1     1     1    0    0\n",
       "red cat eats     1    0     1     0    0    1\n",
       "the hot dog      0    1     0     0    1    0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [ 'the red dog', 'cat eats dog', 'dog eats food',\n",
    "         'red cat eats', 'the hot dog']\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vectorizer.fit(texts)\n",
    "x = vectorizer.transform(texts)\n",
    "columns = vectorizer.get_feature_names()\n",
    "pd.DataFrame(x.todense(), columns=columns, index=texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Note that the word `the` was removed here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# N-Grams\n",
    "\n",
    "N-Grams is a way we can use to count for the context in the text, the bigger n-gram range the bigger context you can capture but also more features to generate, so be careful not to break your memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T22:21:27.551701Z",
     "start_time": "2021-11-07T22:21:27.531929Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>cat eats</th>\n",
       "      <th>dog</th>\n",
       "      <th>dog eats</th>\n",
       "      <th>eats</th>\n",
       "      <th>eats dog</th>\n",
       "      <th>eats food</th>\n",
       "      <th>food</th>\n",
       "      <th>hot</th>\n",
       "      <th>hot dog</th>\n",
       "      <th>red</th>\n",
       "      <th>red cat</th>\n",
       "      <th>red dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the red dog</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat eats dog</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog eats food</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red cat eats</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the hot dog</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cat  cat eats  dog  dog eats  eats  eats dog  eats food  food  \\\n",
       "the red dog      0         0    1         0     0         0          0     0   \n",
       "cat eats dog     1         1    1         0     1         1          0     0   \n",
       "dog eats food    0         0    1         1     1         0          1     1   \n",
       "red cat eats     1         1    0         0     1         0          0     0   \n",
       "the hot dog      0         0    1         0     0         0          0     0   \n",
       "\n",
       "               hot  hot dog  red  red cat  red dog  \n",
       "the red dog      0        0    1        0        1  \n",
       "cat eats dog     0        0    0        0        0  \n",
       "dog eats food    0        0    0        0        0  \n",
       "red cat eats     0        0    1        1        0  \n",
       "the hot dog      1        1    0        0        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [ 'the red dog', 'cat eats dog', 'dog eats food',\n",
    "         'red cat eats', 'the hot dog']\n",
    "vectorizer = CountVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "vectorizer.fit(texts)\n",
    "x = vectorizer.transform(texts)\n",
    "columns = vectorizer.get_feature_names()\n",
    "pd.DataFrame(x.todense(), columns=columns, index=texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TFIDF\n",
    "\n",
    "Instead of just counting the frequency of each word, each word here is weighted using TF-IDF\n",
    "\n",
    "$$W_{x, y} = tf_{x, y} \\times log(\\frac{N}{df_x})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T22:21:27.593491Z",
     "start_time": "2021-11-07T22:21:27.553869Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>cat eats</th>\n",
       "      <th>dog</th>\n",
       "      <th>dog eats</th>\n",
       "      <th>eats</th>\n",
       "      <th>eats dog</th>\n",
       "      <th>eats food</th>\n",
       "      <th>food</th>\n",
       "      <th>hot</th>\n",
       "      <th>hot dog</th>\n",
       "      <th>red</th>\n",
       "      <th>red cat</th>\n",
       "      <th>red dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the red dog</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.401565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.575063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.712775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat eats dog</th>\n",
       "      <td>0.460631</td>\n",
       "      <td>0.460631</td>\n",
       "      <td>0.321658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382365</td>\n",
       "      <td>0.57094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog eats food</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290314</td>\n",
       "      <td>0.515306</td>\n",
       "      <td>0.345106</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.515306</td>\n",
       "      <td>0.515306</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red cat eats</th>\n",
       "      <td>0.437464</td>\n",
       "      <td>0.437464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363135</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.437464</td>\n",
       "      <td>0.542226</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the hot dog</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.370086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6569</td>\n",
       "      <td>0.6569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    cat  cat eats       dog  dog eats      eats  eats dog  \\\n",
       "the red dog    0.000000  0.000000  0.401565  0.000000  0.000000   0.00000   \n",
       "cat eats dog   0.460631  0.460631  0.321658  0.000000  0.382365   0.57094   \n",
       "dog eats food  0.000000  0.000000  0.290314  0.515306  0.345106   0.00000   \n",
       "red cat eats   0.437464  0.437464  0.000000  0.000000  0.363135   0.00000   \n",
       "the hot dog    0.000000  0.000000  0.370086  0.000000  0.000000   0.00000   \n",
       "\n",
       "               eats food      food     hot  hot dog       red   red cat  \\\n",
       "the red dog     0.000000  0.000000  0.0000   0.0000  0.575063  0.000000   \n",
       "cat eats dog    0.000000  0.000000  0.0000   0.0000  0.000000  0.000000   \n",
       "dog eats food   0.515306  0.515306  0.0000   0.0000  0.000000  0.000000   \n",
       "red cat eats    0.000000  0.000000  0.0000   0.0000  0.437464  0.542226   \n",
       "the hot dog     0.000000  0.000000  0.6569   0.6569  0.000000  0.000000   \n",
       "\n",
       "                red dog  \n",
       "the red dog    0.712775  \n",
       "cat eats dog   0.000000  \n",
       "dog eats food  0.000000  \n",
       "red cat eats   0.000000  \n",
       "the hot dog    0.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "texts = [ 'the red dog', 'cat eats dog', 'dog eats food',\n",
    "         'red cat eats', 'the hot dog']\n",
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "vectorizer.fit(texts)\n",
    "x = vectorizer.transform(texts)\n",
    "columns = vectorizer.get_feature_names()\n",
    "pd.DataFrame(x.todense(), columns=columns, index=texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can already build some application using only these, let's try a very quick one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T22:21:28.605142Z",
     "start_time": "2021-11-07T22:21:27.598038Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA : With all the recent problems the Indians have been having\n",
      "with their pitching staff I have heard numerous names\n",
      "thrown around about who could solve their problem.\n",
      "\n",
      "One name I have not heard is Mike Soper (RP).  As far as\n",
      "I know, Soper has had pretty good minor league stats.\n",
      "Why not give the kid a chance?  Anyone know anything about\n",
      "this guy?\n",
      "\n",
      "-- \n",
      "LABEL: rec.sport.baseball\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "from termcolor import colored\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = fetch_20newsgroups(subset='test', remove=['headers', 'footers', 'quotes'],\n",
    "                         categories=['rec.autos', 'comp.windows.x', \n",
    "                                     'soc.religion.christian', 'rec.sport.baseball'])\n",
    "x = data.data\n",
    "y = [data.target_names[i] for i in data.target]\n",
    "print(f'DATA : {x[0]}')\n",
    "print(f'LABEL: {y[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T22:21:28.610309Z",
     "start_time": "2021-11-07T22:21:28.606475Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'rec.sport.baseball': 397,\n",
       "         'soc.religion.christian': 398,\n",
       "         'comp.windows.x': 395,\n",
       "         'rec.autos': 396})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T22:21:28.620777Z",
     "start_time": "2021-11-07T22:21:28.612758Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's try to get the top-5 similar articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T22:21:29.113768Z",
     "start_time": "2021-11-07T22:21:28.623397Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vectorizer.fit(x_train)\n",
    "x_train_v = vectorizer.transform(x_train)\n",
    "x_test_v = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T22:21:59.507846Z",
     "start_time": "2021-11-07T22:21:59.461702Z"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 106\n",
      "True label: \u001b[32mrec.sport.baseball\u001b[0m\n",
      "0 nearest label is \u001b[32mrec.sport.baseball\u001b[0m similarity: \u001b[33m0.283\u001b[0m\n",
      "1 nearest label is \u001b[32mrec.sport.baseball\u001b[0m similarity: \u001b[33m0.28\u001b[0m\n",
      "2 nearest label is \u001b[32mrec.sport.baseball\u001b[0m similarity: \u001b[33m0.239\u001b[0m\n",
      "ID: 290\n",
      "True label: \u001b[32msoc.religion.christian\u001b[0m\n",
      "0 nearest label is \u001b[32msoc.religion.christian\u001b[0m similarity: \u001b[33m0.404\u001b[0m\n",
      "1 nearest label is \u001b[32msoc.religion.christian\u001b[0m similarity: \u001b[33m0.335\u001b[0m\n",
      "2 nearest label is \u001b[32msoc.religion.christian\u001b[0m similarity: \u001b[33m0.228\u001b[0m\n",
      "ID: 314\n",
      "True label: \u001b[32mrec.sport.baseball\u001b[0m\n",
      "0 nearest label is \u001b[32mrec.sport.baseball\u001b[0m similarity: \u001b[33m0.206\u001b[0m\n",
      "1 nearest label is \u001b[32mrec.sport.baseball\u001b[0m similarity: \u001b[33m0.154\u001b[0m\n",
      "2 nearest label is \u001b[32mrec.sport.baseball\u001b[0m similarity: \u001b[33m0.154\u001b[0m\n",
      "ID: 160\n",
      "True label: \u001b[32mrec.autos\u001b[0m\n",
      "0 nearest label is \u001b[32mrec.autos\u001b[0m similarity: \u001b[33m0.205\u001b[0m\n",
      "1 nearest label is \u001b[32mrec.autos\u001b[0m similarity: \u001b[33m0.182\u001b[0m\n",
      "2 nearest label is \u001b[32mrec.autos\u001b[0m similarity: \u001b[33m0.177\u001b[0m\n",
      "ID: 165\n",
      "True label: \u001b[32msoc.religion.christian\u001b[0m\n",
      "0 nearest label is \u001b[32msoc.religion.christian\u001b[0m similarity: \u001b[33m0.467\u001b[0m\n",
      "1 nearest label is \u001b[32msoc.religion.christian\u001b[0m similarity: \u001b[33m0.422\u001b[0m\n",
      "2 nearest label is \u001b[32msoc.religion.christian\u001b[0m similarity: \u001b[33m0.379\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for i in random.choices(range(0, len(x_test)), k=5):\n",
    "    print(f\"ID: {i}\")\n",
    "    print(\"True label:\", colored(y_test[i], 'green'))\n",
    "    distances = cosine_similarity(x_test_v[i], x_train_v).flatten()\n",
    "    indices = np.argsort(distances)[::-1]\n",
    "    for _, j in enumerate(indices[:3]):\n",
    "        print(f\"{_} nearest label is {colored(y_train[j], 'green' if y_train[j]==y_test[i] else 'red')}\",\n",
    "             f\"similarity: {colored(round(distances[j], 3), 'yellow')}\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
